require_relative '../lib/daimond'

puts "=== Daimond MNIST with Rust Backend ==="
puts "Rust available: #{defined?(Daimond::Rust) ? '‚úÖ YES' : '‚ùå NO'}"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ Rust —Ä–µ–∞–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
if defined?(Daimond::Rust)
  test_tensor = Daimond::Rust::Tensor.zeros(5, 5)
  puts "Rust tensor shape: #{test_tensor.shape}"
  puts "‚úÖ Rust backend loaded successfully!\n\n"
else
  puts "‚ö†Ô∏è  Falling back to pure Ruby\n\n"
end

puts "Loading MNIST dataset..."
# –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –Ω–∞ 10000, –ø–æ—Ç–æ–º –º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å .first(10000)
train_images = Daimond::Data::MNIST.load_images('train-images-idx3-ubyte.gz')
train_labels = Daimond::Data::MNIST.load_labels('train-labels-idx1-ubyte.gz')

sample_size = 10000  # –ú–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 60000 –µ—Å–ª–∏ 10000 —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ
train_images = train_images.first(sample_size)
train_labels = train_labels.first(sample_size)

puts "Using #{sample_size} samples"

test_images = Daimond::Data::MNIST.load_images('t10k-images-idx3-ubyte.gz')
test_labels = Daimond::Data::MNIST.load_labels('t10k-labels-idx1-ubyte.gz')

puts "Train: #{train_images.length}, Test: #{test_images.length}"

train_loader = Daimond::Data::DataLoader.new(train_images, train_labels, batch_size: 32, shuffle: true)

class MNISTNet < Daimond::NN::Module
  attr_reader :fc1, :fc2

  def initialize
    super()
    @fc1 = Daimond::NN::Linear.new(784, 128)
    @fc2 = Daimond::NN::Linear.new(128, 10)
    @parameters = @fc1.parameters + @fc2.parameters
  end

  def forward(x)
    h = @fc1.forward(x).relu
    @fc2.forward(h).softmax
  end
end

model = MNISTNet.new
optimizer = Daimond::Optim::SGD.new(model.parameters, lr: 0.1, momentum: 0.9)
criterion = Daimond::Loss::CrossEntropyLoss.new

puts "\nTraining..."
epochs = 5
start_time = Time.now

epochs.times do |epoch|
  total_loss = 0
  correct = 0
  total = 0

  # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ Rust usage
  rust_operations = 0
  ruby_operations = 0

  train_loader.each_batch do |x, y|
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    if x.shape[0] > 100 && defined?(Daimond::Rust)
      rust_operations += 1
    else
      ruby_operations += 1
    end

    pred = model.forward(x)
    loss = criterion.call(pred, y)

    total_loss += loss.data[0]

    batch_size = x.shape[0]
    batch_size.times do |i|
      predicted_class = pred.data[i, true].argmax
      correct += 1 if predicted_class == y.data[i]
      total += 1
    end

    optimizer.zero_grad
    loss.backward!
    optimizer.step
  end

  avg_loss = total_loss / train_loader.batches_count
  accuracy = 100.0 * correct / total
  puts "Epoch #{epoch + 1}/#{epochs}: Loss = #{avg_loss.round(4)}, Accuracy = #{accuracy.round(2)}%"
  puts "  Backend: #{rust_operations}x Rust, #{ruby_operations}x Ruby" if epoch == 0

  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —ç–ø–æ—Ö—É
  elapsed = Time.now - start_time
  avg_epoch_time = elapsed / (epoch + 1)
  remaining = avg_epoch_time * (epochs - epoch - 1)
  puts "  Time: #{elapsed.round(1)}s elapsed, ~#{remaining.round(1)}s remaining"
end

total_time = Time.now - start_time
puts "\nüéâ Training complete in #{total_time.round(2)}s!"

# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
puts "\nTesting on first test image..."
test_x = Daimond::Tensor.new([test_images[0]])
pred = model.forward(test_x)
predicted_digit = pred.data[0, true].argmax
puts "Predicted: #{predicted_digit}, Actual: #{test_labels[0]}"

puts "\n=== BACKEND STATS ==="
puts "Rust operations: #{$rust_count || 0}"
puts "Ruby operations: #{$ruby_count || 0}"

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å pure Ruby (–µ—Å–ª–∏ Rust –±—ã–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω)
if defined?(Daimond::Rust)
  puts "\nüí° Tip: Run with Ruby-only by removing 'require_relative' for Rust to compare speeds"
end